{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия и анализ изображений\n",
    "\n",
    "\n",
    "В этом ноутбуке предлагается построить классификатор изображений на основе логистической регрессии.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Постановка задачи ##\n",
    "\n",
    "\n",
    "**Задача**: Есть [датасет](https://drive.google.com/file/d/15tOimf2QYWsMtPJXTUCwgZaOTF8Nxcsm/view?usp=sharing) (\"catvnoncat.h5\") состоящий из:\n",
    "    - обучающей выборки из m_train изображений, помеченных \"cat\" (y=1) или \"non-cat\" (y=0)\n",
    "    - тестовой выборки m_test изображений, помеченных \"cat\" или \"non-cat\"\n",
    "    - каждое цветное изображение имеет размер (src_size, src_size, 3), где 3 - число каналов (RGB).\n",
    "    Таким образом, каждый слой - квадрат размера src_size x src_size$.\n",
    "\n",
    "Давайте построим простой алгоритм классификации изображений на классы \"cat\"/\"non-cat\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "**Recap**:\n",
    "\n",
    "Для каждого примера $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "Функция потерь:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Загрузка данных и визуализация ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_data = h5py.File(r\"data\\train_catvnoncat.h5\", \"r\")\n",
    "    train_set_x_orig = np.array(train_data[\"train_set_x\"][:]) # признаки\n",
    "    train_set_y_orig = np.array(train_data[\"train_set_y\"][:]) # метки классов\n",
    "\n",
    "    test_data = h5py.File(r\"data\\test_catvnoncat.h5\", \"r\")\n",
    "    test_set_x_orig = np.array(test_data[\"test_set_x\"][:]) # признаки\n",
    "    test_set_y_orig = np.array(test_data[\"test_set_y\"][:]) # метки классов\n",
    "\n",
    "    classes = np.array(test_data[\"list_classes\"][:]) # the list of classes\n",
    "    classes = np.array(list(map(lambda x: x.decode('utf-8'), classes)))\n",
    "    \n",
    "    train_set_y = train_set_y_orig.reshape(train_set_y_orig.shape[0])\n",
    "    test_set_y = test_set_y_orig.reshape(test_set_y_orig.shape[0])\n",
    "    return train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цветные изображения в формате RGB представлены в виде трёхмерных numpy.array.\n",
    "\n",
    "Порядок измерений $H \\times W \\times C$: $H$ - высота, $W$ - ширина и $C$ - число каналов.\n",
    "\n",
    "Значение каждого пиксела находится в интервале $[0;255]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def show_image_interact(i=0):\n",
    "    f, ax = plt.subplots(1,4, figsize=(15,20), sharey=True)\n",
    "    \n",
    "    ax[0].imshow(train_set_x_orig[i])\n",
    "    ax[0].set_title('RGB image')\n",
    "    ax[1].imshow(train_set_x_orig[i][:,:,0], cmap='gray')\n",
    "    ax[1].set_title('R channel')\n",
    "    ax[2].imshow(train_set_x_orig[i][:,:,1], cmap='gray')\n",
    "    ax[2].set_title('G channel')\n",
    "    ax[3].imshow(train_set_x_orig[i][:,:,2], cmap='gray')\n",
    "    ax[3].set_title('B channel')\n",
    "    \n",
    "    print(\"y = {} belongs to '{}' class.\".format(str(train_set_y[i]),classes[np.squeeze(train_set_y[i])]))\n",
    "\n",
    "interact(show_image_interact,\n",
    "         i=widgets.IntSlider(min=0, max=len(train_set_y)-1, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с данными полезно будет сохранить размерности входных изображений для дальнейшей обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "src_size = train_set_x_orig.shape[1]\n",
    "\n",
    "print (\"Размер обучающей выборки: m_train = \" + str(m_train))\n",
    "print (\"Размер тестовой выборки: m_test = \" + str(m_test))\n",
    "print (\"Ширина/Высота каждого изображения: src_size = \" + str(src_size))\n",
    "print (\"Размерны трёхмерной матрицы для каждого изображения: (\" + str(src_size) + \", \" + str(src_size) + \", 3)\")\n",
    "print (\"Размерность train_set_x: \" + str(train_set_x_orig.shape))\n",
    "print (\"Размерность train_set_y: \" + str(train_set_y.shape))\n",
    "print (\"Размерность test_set_x: \" + str(test_set_x_orig.shape))\n",
    "print (\"Размерность test_set_y: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Предварительная обработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем входные изображения размера (num_px, num_px, 3) в вектор признаков размера (num_px $*$ num_px $*$ 3, 1), чтобы сформировать матрицы объект-признак в виде numpy-array для обучающей и тестовой выборок.\n",
    "\n",
    "Каждой строке матрицы объект-признак соответствует входное развёрнутое в вектор-строку изображение.\n",
    "\n",
    "Помимо этого, для предварительной обработки (препроцессинга) изображений применяют центрирование значений: из значения каждого пиксела вычитается среднее и делят полученное значение на среднеквадратичное отклонение значений пикселей всего изображения.\n",
    "\n",
    "Однако, на практике обычно просто делят значения пикселей на 255 (максимальное значение пикселя).\n",
    "\n",
    "Оформим эти шаги в функцию предварительной обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing_simple(data):\n",
    "    assert type(data) == np.ndarray\n",
    "    assert data.ndim == 4\n",
    "    \n",
    "    n,h,w,c = data.shape\n",
    "    data_vectorized = <ваш код>\n",
    "    data_normalized = <ваш код>\n",
    "    \n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменить размеры входных данных\n",
    "\n",
    "train_set_x_vectorized = image_preprocessing_simple(train_set_x_orig)\n",
    "test_set_x_vectorized = image_preprocessing_simple(test_set_x_orig)\n",
    "\n",
    "print('Train set:')\n",
    "print(\"Размеры train_set_x_vectorized:  {}\".format(str(train_set_x_vectorized.shape)))\n",
    "print(\"Размеры train_set_y:             {}\".format(str(train_set_y.shape)))\n",
    "print(\"Размеры классов 'cat'/'non-cat': {} / {}\".format(sum(train_set_y==1), sum(train_set_y==0)))\n",
    "print('Test set:')\n",
    "print(\"Размеры test_set_x_vectorized:   {}\".format(str(test_set_x_vectorized.shape)))\n",
    "print(\"Размеры test_set_y:              {}\".format(str(test_set_y.shape)))\n",
    "print(\"Размеры классов 'cat'/'non-cat': {} / {}\".format(sum(test_set_y==1), sum(test_set_y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: Какую метрику качества стоит использовать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим  модель с параметрами по умолчанию и посмотрим, как хорошо она справится с задачей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = # <ваш  код>\n",
    "\n",
    "score = <ваш код> \n",
    "print('Точность для простой модели с параметрами по умолчанию: {:.4f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "y_predicted = clf.predict(test_set_x_vectorized)\n",
    "correct_score = <ваш код>\n",
    "print('<Имя метрики> для простой модели: {:.4f}'.format(correct_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подобрать параметры регуляризации в надежде, что это повысит точность предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<ваш код>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Оптимальные параметры: {}'.format(<ваш код>))\n",
    "print('Наилучшее значение метрики качества: {}'.format(<ваш код>))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с оптимальными параметрами на всей обучающей выборке и посмотрим на метрики качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = <ваш код>\n",
    "best_clf.fit(train_set_x_vectorized, train_set_y)\n",
    "\n",
    "y_predicted = best_clf.predict(test_set_x_vectorized)\n",
    "metric_score = <ваш код>(y_predicted, test_set_y)\n",
    "print('Optimal model hyperparameters accuracy score: {:.4f}'.format(metric_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Анализ ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_outlier = (y_predicted != test_set_y)\n",
    "test_outliers_x, test_outliers_y, predicted_y = test_set_x_orig[is_outlier], test_set_y[is_outlier], y_predicted[is_outlier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_outliers(i=0):\n",
    "    f = plt.figure(figsize=(5,5))\n",
    "    plt.imshow(test_outliers_x[i])\n",
    "    plt.title('RGB image')\n",
    "    \n",
    "    fmt_string = \"Sample belongs to '{}' class, but '{}' is predicted'\"\n",
    "    print(fmt_string.format(classes[test_outliers_y[i]], classes[predicted_y[i]]))\n",
    "\n",
    "interact(show_image_outliers,\n",
    "         i=widgets.IntSlider(min=0, max=len(test_outliers_y)-1, step=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: Как по-вашему можно повысить точность? Каким недостатком обладает данный подход к классификации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Модель с аугментациями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно увеличить количество данных для обучения?\n",
    "\n",
    "Сформировать новые примеры из уже имеющихся!\n",
    "\n",
    "Например, можно пополнить class 'cat' обучающей выборки [зеркально отображёнными](https://docs.scipy.org/doc/numpy/reference/generated/numpy.fliplr.html) изображениями котов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_sample(src, label):\n",
    "    <ваш код>\n",
    "\n",
    "def image_preprocessing_augment(data, labels):\n",
    "    assert type(data) == np.ndarray\n",
    "    assert data.ndim == 4\n",
    "    \n",
    "    ## ВАШ КОД ##\n",
    "    \n",
    "    \n",
    "    data_augmented = \n",
    "    labels_augmented = \n",
    "    ## ВАШ КОД ЗАКАНЧИВАЕТСЯ ЗДЕСЬ ##\n",
    "    \n",
    "    n,h,w,c = data_augmented.shape\n",
    "    data_vectorized = data_augmented.reshape(n, -1) # <ваш код>\n",
    "    data_normalized = data_vectorized / 255\n",
    "    \n",
    "    return data_normalized, labels_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_augmented, train_set_y_augmented = image_preprocessing_augment(train_set_x_orig, train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(train_set_x_augmented, train_set_y_augmented)\n",
    "y_pred = clf.predict(test_set_x_vectorized)\n",
    "print('F-мера для модели с аугментациями: {:.4f}'.format(f1_score(y_pred, test_set_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверьте работу классификатора на своей картинке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека [OpenCV](https://opencv.org) для работы с изображениями для [python](https://pypi.org/project/opencv-python/):\n",
    "\n",
    "`pip install opencv-python`\n",
    "\n",
    "Вместе с contrib-модулями:\n",
    "\n",
    "`pip install opencv-contrib-python`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Путь к картинке на вашем ПК\n",
    "fname = \"cat-non-cat.jpg\"\n",
    "# Считываем картинку через scipy\n",
    "src = cv2.cvtColor(cv2.imread((fname)), cv2.COLOR_BGR2RGB)\n",
    "src_resized = cv2.resize(src, (src_size,src_size), interpolation=cv2.INTER_LINEAR).reshape(1, src_size*src_size*3)\n",
    "my_image_predict = clf.predict(src_resized)[0]\n",
    "\n",
    "plt.imshow(src)\n",
    "print(\"Алгоритм говорит, что это '{}': {}\".format(my_image_predict, classes[my_image_predict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
